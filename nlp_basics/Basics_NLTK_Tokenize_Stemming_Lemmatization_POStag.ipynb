{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPShJ20MV/zwQxmkV/AWoc0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Liza-IITP/Machine-Learning/blob/main/nlp_basics/Basics_NLTK_Tokenize_Stemming_Lemmatization_POStag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3l93eiFxO0X",
        "outputId": "24220833-f44f-416c-e0b2-4b3e582471a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize, wordpunct_tokenize"
      ],
      "metadata": {
        "id": "RuGoZuQQxRCi"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph = \"\"\"As a scientific endeavour,\n",
        "machine learning grew out of the quest for artificial intelligence (AI).\n",
        "In the early days of AI as an academic discipline,\n",
        "some researchers were interested in having machines learn from data.\n",
        "They attempted to approach the problem with various symbolic methods,\n",
        "as well as what were then termed \"neural networks\";\n",
        "these were mostly perceptrons and other models\n",
        "that were later found to be reinventions of the generalised linear models of statistics.\n",
        "Don't you think it's great how things have developed so rapidly in just few years ?\"\"\""
      ],
      "metadata": {
        "id": "H7HttbvExSvy"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "word_tokenize(paragraph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lsJWa5hxqmT",
        "outputId": "627be92d-277d-4a48-dea3-8a9015e39fa0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['As',\n",
              " 'a',\n",
              " 'scientific',\n",
              " 'endeavour',\n",
              " ',',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'grew',\n",
              " 'out',\n",
              " 'of',\n",
              " 'the',\n",
              " 'quest',\n",
              " 'for',\n",
              " 'artificial',\n",
              " 'intelligence',\n",
              " '(',\n",
              " 'AI',\n",
              " ')',\n",
              " '.',\n",
              " 'In',\n",
              " 'the',\n",
              " 'early',\n",
              " 'days',\n",
              " 'of',\n",
              " 'AI',\n",
              " 'as',\n",
              " 'an',\n",
              " 'academic',\n",
              " 'discipline',\n",
              " ',',\n",
              " 'some',\n",
              " 'researchers',\n",
              " 'were',\n",
              " 'interested',\n",
              " 'in',\n",
              " 'having',\n",
              " 'machines',\n",
              " 'learn',\n",
              " 'from',\n",
              " 'data',\n",
              " '.',\n",
              " 'They',\n",
              " 'attempted',\n",
              " 'to',\n",
              " 'approach',\n",
              " 'the',\n",
              " 'problem',\n",
              " 'with',\n",
              " 'various',\n",
              " 'symbolic',\n",
              " 'methods',\n",
              " ',',\n",
              " 'as',\n",
              " 'well',\n",
              " 'as',\n",
              " 'what',\n",
              " 'were',\n",
              " 'then',\n",
              " 'termed',\n",
              " '``',\n",
              " 'neural',\n",
              " 'networks',\n",
              " \"''\",\n",
              " ';',\n",
              " 'these',\n",
              " 'were',\n",
              " 'mostly',\n",
              " 'perceptrons',\n",
              " 'and',\n",
              " 'other',\n",
              " 'models',\n",
              " 'that',\n",
              " 'were',\n",
              " 'later',\n",
              " 'found',\n",
              " 'to',\n",
              " 'be',\n",
              " 'reinventions',\n",
              " 'of',\n",
              " 'the',\n",
              " 'generalised',\n",
              " 'linear',\n",
              " 'models',\n",
              " 'of',\n",
              " 'statistics',\n",
              " '.',\n",
              " 'Do',\n",
              " \"n't\",\n",
              " 'you',\n",
              " 'think',\n",
              " 'it',\n",
              " \"'s\",\n",
              " 'great',\n",
              " 'how',\n",
              " 'things',\n",
              " 'have',\n",
              " 'developed',\n",
              " 'so',\n",
              " 'rapidly',\n",
              " 'in',\n",
              " 'just',\n",
              " 'few',\n",
              " 'years',\n",
              " '?']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wordpunct_tokenize(paragraph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTIiWUg6yn0Q",
        "outputId": "9bb801fd-9695-42eb-b0ee-8c4b9a48d907"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['As',\n",
              " 'a',\n",
              " 'scientific',\n",
              " 'endeavour',\n",
              " ',',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'grew',\n",
              " 'out',\n",
              " 'of',\n",
              " 'the',\n",
              " 'quest',\n",
              " 'for',\n",
              " 'artificial',\n",
              " 'intelligence',\n",
              " '(',\n",
              " 'AI',\n",
              " ').',\n",
              " 'In',\n",
              " 'the',\n",
              " 'early',\n",
              " 'days',\n",
              " 'of',\n",
              " 'AI',\n",
              " 'as',\n",
              " 'an',\n",
              " 'academic',\n",
              " 'discipline',\n",
              " ',',\n",
              " 'some',\n",
              " 'researchers',\n",
              " 'were',\n",
              " 'interested',\n",
              " 'in',\n",
              " 'having',\n",
              " 'machines',\n",
              " 'learn',\n",
              " 'from',\n",
              " 'data',\n",
              " '.',\n",
              " 'They',\n",
              " 'attempted',\n",
              " 'to',\n",
              " 'approach',\n",
              " 'the',\n",
              " 'problem',\n",
              " 'with',\n",
              " 'various',\n",
              " 'symbolic',\n",
              " 'methods',\n",
              " ',',\n",
              " 'as',\n",
              " 'well',\n",
              " 'as',\n",
              " 'what',\n",
              " 'were',\n",
              " 'then',\n",
              " 'termed',\n",
              " '\"',\n",
              " 'neural',\n",
              " 'networks',\n",
              " '\";',\n",
              " 'these',\n",
              " 'were',\n",
              " 'mostly',\n",
              " 'perceptrons',\n",
              " 'and',\n",
              " 'other',\n",
              " 'models',\n",
              " 'that',\n",
              " 'were',\n",
              " 'later',\n",
              " 'found',\n",
              " 'to',\n",
              " 'be',\n",
              " 'reinventions',\n",
              " 'of',\n",
              " 'the',\n",
              " 'generalised',\n",
              " 'linear',\n",
              " 'models',\n",
              " 'of',\n",
              " 'statistics',\n",
              " '.',\n",
              " 'Don',\n",
              " \"'\",\n",
              " 't',\n",
              " 'you',\n",
              " 'think',\n",
              " 'it',\n",
              " \"'\",\n",
              " 's',\n",
              " 'great',\n",
              " 'how',\n",
              " 'things',\n",
              " 'have',\n",
              " 'developed',\n",
              " 'so',\n",
              " 'rapidly',\n",
              " 'in',\n",
              " 'just',\n",
              " 'few',\n",
              " 'years',\n",
              " '?']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokenize(paragraph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXOeHLE8zNMc",
        "outputId": "bdbc5ee1-28cc-4874-c451-669dbd5916c5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['As a scientific endeavour, \\nmachine learning grew out of the quest for artificial intelligence (AI).',\n",
              " 'In the early days of AI as an academic discipline, \\nsome researchers were interested in having machines learn from data.',\n",
              " 'They attempted to approach the problem with various symbolic methods, \\nas well as what were then termed \"neural networks\"; \\nthese were mostly perceptrons and other models \\nthat were later found to be reinventions of the generalised linear models of statistics.',\n",
              " \"Don't you think it's great how things have developed so rapidly in just few years ?\"]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "text = \"I love NLP. Don't panic!\"\n",
        "\n",
        "print(tokenizer.tokenize(text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMEYVKjJ0JEk",
        "outputId": "299705f4-3377-4190-c6db-c6f32b6a0dd0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'love', 'NLP.', 'Do', \"n't\", 'panic', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"The children were playing happily in the gardens\"\n",
        "tokens = nltk.word_tokenize(sentence)\n",
        "print(tokens)\n",
        "\n",
        "from nltk.stem import RegexpStemmer\n",
        "\n",
        "regexp_stemmer = RegexpStemmer('ing$|s$|ed$', min=4)\n",
        "print([regexp_stemmer.stem(word) for word in tokens])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGPkWuaD93Wi",
        "outputId": "7f1aa9ac-67c5-460b-ae7c-a21c82d158ac"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'children', 'were', 'playing', 'happily', 'in', 'the', 'gardens']\n",
            "['The', 'children', 'were', 'play', 'happily', 'in', 'the', 'garden']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"running\", \"runs\", \"ran\", \"better\", \"studies\", \"studying\"]\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "[ps.stem(w) for w in words]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdf3rvRA5sVq",
        "outputId": "919aa9c9-bb63-4e43-fe67-7d2f9ccfe7b4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['run', 'run', 'ran', 'better', 'studi', 'studi']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "ss = SnowballStemmer(\"english\")\n",
        "[ss.stem(w) for w in words]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXg5enZS50hs",
        "outputId": "72928a1d-58e3-4ed0-c7ff-cfdf256f0eb3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['run', 'run', 'ran', 'better', 'studi', 'studi']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import LancasterStemmer\n",
        "\n",
        "ls = LancasterStemmer()\n",
        "[ls.stem(w) for w in words]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekdwcN6855QY",
        "outputId": "8f0c6b47-bdca-45b1-e58b-f44b01515a0f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['run', 'run', 'ran', 'bet', 'study', 'study']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhBVW2ye59FZ",
        "outputId": "d543e776-c6b8-49c8-822b-b0d2f9903d5d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "[lemmatizer.lemmatize(w) for w in words]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EF5NbDd5_fi",
        "outputId": "f954cf59-ee34-40a7-fcdf-827f7ca30015"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['running', 'run', 'ran', 'better', 'study', 'studying']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "sentence = \"\"\"Today morning, Arthur felt very good.\"\"\"\n",
        "tokens = nltk.word_tokenize(sentence)\n",
        "tagged = nltk.pos_tag(tokens)\n",
        "print(tagged)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWGTxjoB7BwR",
        "outputId": "acc04374-e0d7-48ac-fed1-26d6e3180449"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Today', 'NN'), ('morning', 'NN'), (',', ','), ('Arthur', 'NNP'), ('felt', 'VBD'), ('very', 'RB'), ('good', 'JJ'), ('.', '.')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    }
  ]
}