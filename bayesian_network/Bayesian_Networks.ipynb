{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOf4weBz96dJUEbpODbReWv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Liza-IITP/Linear-Logistic/blob/main/Bayesian_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Bayesian Networks\n",
        "import networkx as nx\n",
        "from itertools import product\n",
        "import matplotlib.pyplot as plt\n",
        "class BayesNet(nx.DiGraph):\n",
        "    def __mod__(self, node): return self.nodes[node]['V']\n",
        "    def __mul__(self, other): n, v = other; self.add_node(n, V=tuple(v), CPT=None); return self\n",
        "    def __truediv__(self, other):\n",
        "        for o in other:  self.remove_node(o); return self\n",
        "    def __add__(self, other): self.add_edge(*other); return self\n",
        "    def __sub__(self, other): self.remove_edge(*other); return self\n",
        "    def __call__(self, node, evi=None): return self.nodes[node]['CPT'] if evi is None else self.nodes[node]['CPT'][evi]\n",
        "    def __invert__(self,):\n",
        "        for n in self.nodes:\n",
        "            pdn = self.predecessors(n)\n",
        "            vals = (self)%(n) # set of possible vals\n",
        "            pvals=[(self)%(p) for p in pdn] # list of sets\n",
        "            self.nodes[n]['CPT'] = {combo:{k:0.0 for k in vals} for combo in product(*pvals)}\n",
        "            self.nodes[n]['P'] = tuple(pdn)\n",
        "        return self\n",
        "    def check(self, delta=1e-15):\n",
        "        for n in self.nodes:\n",
        "            print(f'Node [{n}]')\n",
        "            cpt = self.nodes[n]['CPT']\n",
        "            for k, v in cpt.items():\n",
        "                sumprobs = sum(list(v.values()))\n",
        "                print(f'\\tEvi [{k}], probs={v}, {sumprobs=}, {\"✅\" if abs(1 - sumprobs) < delta else \"⛔\"}')\n",
        "    def plot(self, pos=None, figsize=(5,5), node_color='white', edge_color='black', node_size=500, font_size=10, arrow_size=10, seed=None):\n",
        "        if not pos: pos = nx.spring_layout(self, seed=seed)\n",
        "        plt.figure(figsize=figsize)\n",
        "        nx.draw(self, pos, with_labels=True, node_size=node_size, node_color=node_color, font_size=font_size, font_weight=\"bold\", arrowsize=arrow_size, edgecolors=edge_color,)\n",
        "        plt.title(f\"Nodes={len(self.nodes)} Edges={len(self.edges)}\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "b9_gOpW1WTug"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5uYUneYVUAy",
        "outputId": "55496e2f-b8ad-48d8-8e21-4b276ee41821"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node [E]\n",
            "\tEvi [()], probs={'E0': 0.9997, 'E1': 0.0003}, sumprobs=1.0, ✅\n",
            "Node [B]\n",
            "\tEvi [()], probs={'B0': 0.9999, 'B1': 0.0001}, sumprobs=1.0, ✅\n",
            "Node [A]\n",
            "\tEvi [('E0', 'B0')], probs={'A0': 0.99, 'A1': 0.01}, sumprobs=1.0, ✅\n",
            "\tEvi [('E0', 'B1')], probs={'A0': 0.05, 'A1': 0.95}, sumprobs=1.0, ✅\n",
            "\tEvi [('E1', 'B0')], probs={'A0': 0.8, 'A1': 0.2}, sumprobs=1.0, ✅\n",
            "\tEvi [('E1', 'B1')], probs={'A0': 0.04, 'A1': 0.96}, sumprobs=1.0, ✅\n",
            "Node [R]\n",
            "\tEvi [('E0',)], probs={'R0': 0.9998, 'R1': 0.0002}, sumprobs=1.0, ✅\n",
            "\tEvi [('E1',)], probs={'R0': 0.1, 'R1': 0.9}, sumprobs=1.0, ✅\n",
            "Node [W]\n",
            "\tEvi [('A0',)], probs={'W0': 0.6, 'W1': 0.4}, sumprobs=1.0, ✅\n",
            "\tEvi [('A1',)], probs={'W0': 0.2, 'W1': 0.8}, sumprobs=1.0, ✅\n",
            "Node [G]\n",
            "\tEvi [('A0',)], probs={'G0': 0.96, 'G1': 0.04}, sumprobs=1.0, ✅\n",
            "\tEvi [('A1',)], probs={'G0': 0.6, 'G1': 0.4}, sumprobs=1.0, ✅\n",
            "Q.1-> ANS:  Probability of all events intersecting:\n",
            "0.0031980803519808\n",
            "Q.2-> ANS :  Probability of all events intersecting:\n",
            "0.5698979187229786\n"
          ]
        }
      ],
      "source": [
        "\n",
        "BN = BayesNet()\n",
        "BN *= ('E', ('E0', 'E1'))\n",
        "BN *= ('B', ('B0', 'B1'))\n",
        "BN *= ('A', ('A0', 'A1'))\n",
        "BN *= ('R', ('R0', 'R1'))\n",
        "BN *= ('W', ('W0', 'W1'))\n",
        "BN *= ('G', ('G0', 'G1'))\n",
        "BN += ('E', 'R')\n",
        "BN += ('E', 'A')\n",
        "BN += ('B', 'A')\n",
        "BN += ('A', 'W')\n",
        "BN += ('A', 'G')\n",
        "~BN\n",
        "BN('A', ('E0', 'B0'))['A1'] = 0.01\n",
        "BN('A', ('E0', 'B0'))['A0'] = 0.99\n",
        "BN('A', ('E1', 'B0'))['A1'] = 0.2\n",
        "BN('A', ('E1', 'B0'))['A0'] = 0.8\n",
        "BN('A', ('E0', 'B1'))['A1'] = 0.95\n",
        "BN('A', ('E0', 'B1'))['A0'] = 0.05\n",
        "BN('A', ('E1', 'B1'))['A1'] = 0.96\n",
        "BN('A', ('E1', 'B1'))['A0'] = 0.04\n",
        "BN('B',())['B1']=0.0001\n",
        "BN('B',())['B0']=0.9999\n",
        "BN('E',())['E1']=0.0003\n",
        "BN('E',())['E0']=0.9997\n",
        "BN('R', ('E0',))['R1'] = 0.0002\n",
        "BN('R', ('E1',))['R1'] = 0.9\n",
        "BN('R', ('E1',))['R0'] = 0.1\n",
        "BN('R', ('E0',))['R0'] = 0.9998\n",
        "BN('W', ('A0',))['W1'] = 0.4\n",
        "BN('W', ('A0',))['W0'] = 0.6\n",
        "BN('W', ('A1',))['W1'] = 0.8\n",
        "BN('W', ('A1',))['W0'] = 0.2\n",
        "BN('G', ('A0',))['G1'] = 0.04\n",
        "BN('G', ('A0',))['G0'] = 0.96\n",
        "BN('G', ('A1',))['G1'] = 0.4\n",
        "BN('G', ('A1',))['G0'] = 0.6\n",
        "BN.check()\n",
        "\n",
        "# q1-A,B',E',W,G,R'\n",
        "\n",
        "def joint_alarm_event(BN):\n",
        "    p_B0 = BN('B', ())['B0']\n",
        "    p_E0 = BN('E', ())['E0']\n",
        "    p_A1 = BN('A', ('E0','B0'))['A1']\n",
        "    p_R0 = BN('R', ('E0',))['R0']\n",
        "    p_W1 = BN('W', ('A1',))['W1']\n",
        "    p_G1 = BN('G', ('A1',))['G1']\n",
        "    return p_B0 * p_E0 * p_A1 * p_R0 * p_W1 * p_G1\n",
        "\n",
        "print(\"Q.1-> ANS:  Probability of all events intersecting:\")\n",
        "print(joint_alarm_event(BN))\n",
        "\n",
        "# q2-A',B',E',W',G',R'\n",
        "\n",
        "def joint_alarm_event2(BN):\n",
        "    p_B0 = BN('B', ())['B0']\n",
        "    p_E0 = BN('E', ())['E0']\n",
        "    p_A0 = BN('A', ('E0','B0'))['A0']\n",
        "    p_R0 = BN('R', ('E0',))['R0']\n",
        "    p_W0 = BN('W', ('A0',))['W0']\n",
        "    p_G0 = BN('G', ('A0',))['G0']\n",
        "    return p_B0 * p_E0 * p_A0 * p_R0 * p_W0 * p_G0\n",
        "\n",
        "print(\"Q.2-> ANS :  Probability of all events intersecting:\")\n",
        "print(joint_alarm_event2(BN))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "\n",
        "V = ['I','loved','the','movie','hated','a','great','poor','acting','good']\n",
        "\n",
        "docs = [\n",
        "    \"I loved the movie\",                # +\n",
        "    \"I hated the movie\",                # -\n",
        "    \"a great movie good movie\",         # +\n",
        "    \"poor acting\",                      # -\n",
        "    \"great acting a good movie\"         # +\n",
        "]\n",
        "\n",
        "labels = ['+','-','+','-','+']  # corresponding labels\n",
        "alpha = 1.0  # Laplace smoothing\n",
        "\n",
        "# Priors\n",
        "N = len(labels)\n",
        "class_counts = Counter(labels)\n",
        "priors = {c: class_counts[c]/N for c in class_counts}\n",
        "\n",
        "# Counts per class\n",
        "word_counts = {c: Counter() for c in class_counts}\n",
        "total_words_in_class = {c: 0 for c in class_counts}\n",
        "for doc, lab in zip(docs, labels):\n",
        "    for w in doc.split():\n",
        "        word_counts[lab][w] += 1\n",
        "        total_words_in_class[lab] += 1\n",
        "\n",
        "V_size = len(V)\n",
        "likelihoods = {c: {} for c in class_counts}\n",
        "for c in class_counts:\n",
        "    denom = total_words_in_class[c] + alpha * V_size\n",
        "    for w in V:\n",
        "        count = word_counts[c][w]\n",
        "        likelihoods[c][w] = (count + alpha) / denom\n",
        "\n",
        "# Sentence\n",
        "sentence = \"I hated the poor acting\"\n",
        "s_words = sentence.split()\n",
        "\n",
        "# Log-posteriors\n",
        "log_post = {}\n",
        "for c in class_counts:\n",
        "    logp = math.log(priors[c])\n",
        "    for w in s_words:\n",
        "        logp += math.log(likelihoods[c].get(w, alpha / (total_words_in_class[c] + alpha * V_size)))\n",
        "    log_post[c] = logp\n",
        "max_log = max(log_post.values())\n",
        "exp_post = {c: math.exp(log_post[c] - max_log) for c in log_post}\n",
        "sum_exp = sum(exp_post.values())\n",
        "posteriors = {c: exp_post[c] / sum_exp for c in exp_post}\n",
        "print(\"Priors:\", priors)\n",
        "print(\"Total words per class:\", total_words_in_class)\n",
        "print(\"Likelihoods (P(word|class)):\\n\")\n",
        "print(pd.DataFrame(likelihoods))\n",
        "print(\"\\nLog-scores:\", log_post)\n",
        "print(\"\\nPosteriors:\", posteriors)\n",
        "print(\"\\nUnnormalized scores (as in the slide):\")\n",
        "for c in class_counts:\n",
        "    score = priors[c]\n",
        "    for w in s_words:\n",
        "        score *= likelihoods[c][w]\n",
        "    print(f\" P({c}) * ∏ P(word|{c}) = {score:.6e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8AMcafqYOqz",
        "outputId": "a9d451b5-a7dc-434c-f13b-8286de4b1aa6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Priors: {'+': 0.6, '-': 0.4}\n",
            "Total words per class: {'+': 14, '-': 6}\n",
            "Likelihoods (P(word|class)):\n",
            "\n",
            "               +       -\n",
            "I       0.083333  0.1250\n",
            "loved   0.083333  0.0625\n",
            "the     0.083333  0.1250\n",
            "movie   0.208333  0.1250\n",
            "hated   0.041667  0.1250\n",
            "a       0.125000  0.0625\n",
            "great   0.125000  0.0625\n",
            "poor    0.041667  0.1250\n",
            "acting  0.083333  0.1250\n",
            "good    0.125000  0.0625\n",
            "\n",
            "Log-scores: {'+': -14.321653233825883, '-': -11.313498440273335}\n",
            "\n",
            "Posteriors: {'+': 0.0470588235294118, '-': 0.9529411764705883}\n",
            "\n",
            "Unnormalized scores (as in the slide):\n",
            " P(+) * ∏ P(word|+) = 6.028164e-07\n",
            " P(-) * ∏ P(word|-) = 1.220703e-05\n"
          ]
        }
      ]
    }
  ]
}
